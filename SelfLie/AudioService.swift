import AVFoundation
import Foundation

// MARK: - Debug Configuration
private struct AudioDebugConfig {
    static let isDebugModeEnabled = false  // Set to true only for debugging
    static let enableDetailedTiming = false
    static let enableHardwarePropertyLogging = false
}

// MARK: - Debug Logging Functions
private func debugLog(_ message: String) {
    if AudioDebugConfig.isDebugModeEnabled {
        print(message)
    }
}

private func timingLog(_ message: String) {
    if AudioDebugConfig.enableDetailedTiming {
        print(message)
    }
}

private func hardwareLog(_ message: String) {
    if AudioDebugConfig.enableHardwarePropertyLogging {
        print(message)
    }
}

@Observable
class AudioService: NSObject {
    private var audioRecorder: AVAudioRecorder?
    private var audioPlayer: AVAudioPlayer?
    private var preparedRecorder: AVAudioRecorder?
    private var preWarmedTimer: Timer?
    
    // Helper function to get hardware-compatible audio settings
    private func getAudioSettings() -> [String: Any] {
        let hardwareSampleRate = AudioSessionManager.shared.getCurrentSampleRate()
        
        hardwareLog("ğŸ™ï¸ [AudioService] Using hardware sample rate: \(hardwareSampleRate) Hz")
        
        return [
            AVFormatIDKey: kAudioFormatMPEG4AAC,
            AVSampleRateKey: hardwareSampleRate, // Use hardware sample rate
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
    }
    
    var isRecording = false
    var isPlaying = false
    var recordingDuration: TimeInterval = 0
    
    private var recordingTimer: Timer?
    private var playbackProgressTimer: Timer?
    
    // æ’­æ”¾å®Œæˆæ£€æµ‹ä¼˜åŒ–ï¼šä½¿ç”¨Continuationæ›¿ä»£è½®è¯¢
    private var playbackCompletionContinuation: CheckedContinuation<Void, Error>?
    
    // Playback progress callbacks
    var onPlaybackProgress: ((TimeInterval, TimeInterval) -> Void)?
    var onPlaybackComplete: (() -> Void)?
    
    override init() {
        super.init()
        // Audio session is now managed by AudioSessionManager
        setupPlaybackInterruptionHandler()
    }
    
    private func setupPlaybackInterruptionHandler() {
        AudioSessionManager.shared.playbackInterruptionHandler = { [weak self] reason in
            guard let self = self else { return }
            
            switch reason {
            case .oldDeviceUnavailable:
                // Switch audio route when device is disconnected - continue playback on speaker
                if self.isPlaying {
                    print("ğŸ§ [AudioService] Audio device disconnected - switching to speaker")
                    self.restartPlaybackForDeviceChange()
                }
            default:
                break
            }
        }
        
        // æ³¨å†Œæ’­æ”¾é‡å¯å›è°ƒ - å½“æ–°è®¾å¤‡è¿æ¥æ—¶é‡æ–°å¯åŠ¨æ’­æ”¾
        AudioSessionManager.shared.playbackRestartHandler = { [weak self] in
            guard let self = self else { return }
            self.restartPlaybackForDeviceChange()
        }
    }
    
    deinit {
        recordingTimer?.invalidate()
        preWarmedTimer?.invalidate()
        playbackProgressTimer?.invalidate()
        cleanupPreparedRecording()
        
        // æ¸…ç†æ’­æ”¾å®Œæˆcontinuation
        playbackCompletionContinuation?.resume(throwing: CancellationError())
        playbackCompletionContinuation = nil
    }
    
    func requestMicrophonePermission() async -> Bool {
        await withCheckedContinuation { continuation in
            AVAudioApplication.requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
    }
    
    func prepareRecording(to url: URL) async throws {
        guard preparedRecorder == nil else { return }
        
        timingLog("â° [AudioService] ğŸ”§ prepareRecording() started")
        let prepareStartTime = Date()
        
        // Ensure directory exists
        let directoryStartTime = Date()
        let directory = url.deletingLastPathComponent()
        try FileManager.default.createDirectory(at: directory, withIntermediateDirectories: true, attributes: nil)
        let directoryDuration = Date().timeIntervalSince(directoryStartTime) * 1000
        timingLog("â° [AudioService] ğŸ“ Directory creation in \(String(format: "%.0fms", directoryDuration))")
        
        let settings = getAudioSettings()
        
        do {
            // Create recorder
            let recorderCreateStartTime = Date()
            preparedRecorder = try AVAudioRecorder(url: url, settings: settings)
            preparedRecorder?.delegate = self
            let recorderCreateDuration = Date().timeIntervalSince(recorderCreateStartTime) * 1000
            timingLog("â° [AudioService] ğŸ™ï¸ AVAudioRecorder created in \(String(format: "%.0fms", recorderCreateDuration))")
            
            // Aggressively prepare recorder
            let prepareToRecordStartTime = Date()
            preparedRecorder?.prepareToRecord()
            let prepareToRecordDuration = Date().timeIntervalSince(prepareToRecordStartTime) * 1000
            timingLog("â° [AudioService] âš¡ prepareToRecord() completed in \(String(format: "%.0fms", prepareToRecordDuration))")
            
            // Pre-warm the timer to eliminate timer creation delay later
            let timerWarmupStartTime = Date()
            preWarmedTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                // This timer will be transferred to recordingTimer when recording starts
                // For now, it does nothing but stays warm
            }
            // Immediately invalidate and keep it ready for transfer
            preWarmedTimer?.invalidate()
            preWarmedTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.recordingDuration = self.audioRecorder?.currentTime ?? 0
            }
            // Keep it paused until we need it
            preWarmedTimer?.invalidate()
            preWarmedTimer = nil // Will recreate when needed
            let timerWarmupDuration = Date().timeIntervalSince(timerWarmupStartTime) * 1000
            timingLog("â° [AudioService] â±ï¸ Timer warmup completed in \(String(format: "%.0fms", timerWarmupDuration))")
            
            let totalPrepareDuration = Date().timeIntervalSince(prepareStartTime) * 1000
            timingLog("â° [AudioService] âœ… prepareRecording() completed in \(String(format: "%.0fms", totalPrepareDuration))")
        } catch {
            preparedRecorder = nil
            debugLog("â° [AudioService] âŒ prepareRecording() failed: \(error.localizedDescription)")
            throw AudioServiceError.recordingFailed
        }
    }
    
    func startPreparedRecording() async throws {
        timingLog("â° [AudioService] ğŸš€ startPreparedRecording() entered")
        let startTime = Date()
        
        guard !isRecording else { 
            debugLog("â° [AudioService] âš ï¸ Already recording, returning")
            return 
        }
        guard let preparedRecorder = preparedRecorder else {
            debugLog("â° [AudioService] âŒ No prepared recorder available")
            throw AudioServiceError.recordingFailed
        }
        
        // Audio session is already configured for .playAndRecord in AudioSessionManager.init()
        // No need to switch - just ensure it's active
        try await AudioSessionManager.shared.ensureSessionActive()
        
        // Ultra-fast recording start: minimize operations
        let recordStartTime = Date()
        
        // Atomic state update and recorder transfer
        isRecording = true
        recordingDuration = 0
        audioRecorder = preparedRecorder
        self.preparedRecorder = nil
        
        // Start recording immediately - this should be instantaneous since recorder is fully prepared
        audioRecorder?.record()
        
        let recordDuration = Date().timeIntervalSince(recordStartTime) * 1000
        timingLog("â° [AudioService] âš¡ Ultra-fast record() completed in \(String(format: "%.0fms", recordDuration))")
        
        // Use pre-warmed timer if available, otherwise create new one
        if let existingTimer = preWarmedTimer {
            timingLog("â° [AudioService] ğŸ”¥ Using pre-warmed timer")
            recordingTimer = existingTimer
            preWarmedTimer = nil
        } else {
            let timerStartTime = Date()
            recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.recordingDuration = self.audioRecorder?.currentTime ?? 0
            }
            let timerDuration = Date().timeIntervalSince(timerStartTime) * 1000
            timingLog("â° [AudioService] â±ï¸ New timer created in \(String(format: "%.0fms", timerDuration))")
        }
        
        let totalDuration = Date().timeIntervalSince(startTime) * 1000
        timingLog("â° [AudioService] âœ… startPreparedRecording() completed in \(String(format: "%.0fms", totalDuration))")
    }
    
    func startRecording(to url: URL) async throws {
        guard !isRecording else { return }
        
        // Ensure directory exists
        let directory = url.deletingLastPathComponent()
        try FileManager.default.createDirectory(at: directory, withIntermediateDirectories: true, attributes: nil)
        
        let settings = getAudioSettings()
        
        do {
            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder?.delegate = self
            audioRecorder?.prepareToRecord()
            audioRecorder?.record()
            
            isRecording = true
            recordingDuration = 0
            
            // Start timer for duration tracking
            recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.recordingDuration = self.audioRecorder?.currentTime ?? 0
            }
        } catch {
            throw AudioServiceError.recordingFailed
        }
    }
    
    func cleanupPreparedRecording() {
        preparedRecorder = nil
        preWarmedTimer?.invalidate()
        preWarmedTimer = nil
    }
    
    func stopRecording() {
        guard isRecording else { return }
        
        audioRecorder?.stop()
        audioRecorder = nil
        isRecording = false
        
        recordingTimer?.invalidate()
        recordingTimer = nil
    }
    
    func playAudio(from url: URL, volume: Float = 1.0) async throws {
        timingLog("â° [AudioService] ğŸµ playAudio() method entered")
        guard !isPlaying else { 
            debugLog("â° [AudioService] âš ï¸ Already playing, returning early")
            return 
        }
        
        // Audio session is already configured for .playAndRecord in AudioSessionManager.init()
        // No need to switch - just ensure it's active
        try await AudioSessionManager.shared.ensureSessionActive()
        
        do {
            timingLog("â° [AudioService] ğŸ”§ Creating AVAudioPlayer")
            let playerCreateStartTime = Date()
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            // æ”¯æŒå¯é€‰éŸ³é‡ï¼Œç”¨äºéšç§æ¨¡å¼é™éŸ³æ’­æ”¾
            audioPlayer?.volume = volume
            audioPlayer?.prepareToPlay()
            let playerCreateDuration = Date().timeIntervalSince(playerCreateStartTime) * 1000
            timingLog("â° [AudioService] âœ… AVAudioPlayer created and prepared in \(String(format: "%.0fms", playerCreateDuration))")
            
            isPlaying = true
            
            // Start progress tracking timer
            startPlaybackProgressTracking()
            
            timingLog("â° [AudioService] â–¶ï¸ Calling audioPlayer.play()")
            let playStartTime = Date()
            audioPlayer?.play()
            let playCallDuration = Date().timeIntervalSince(playStartTime) * 1000
            timingLog("â° [AudioService] âœ… audioPlayer.play() call completed in \(String(format: "%.0fms", playCallDuration))")
            
            // ä¼˜åŒ–ï¼šä½¿ç”¨Continuationç­‰å¾…æ’­æ”¾å®Œæˆï¼Œæ›¿ä»£è½®è¯¢
            timingLog("â° [AudioService] â³ Waiting for playback completion via delegate callback")
            let waitStartTime = Date()
            
            // ä½¿ç”¨continuationç­‰å¾…AVAudioPlayerDelegateå›è°ƒ
            try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
                // ç¡®ä¿æ²¡æœ‰ä¹‹å‰çš„continuationæ®‹ç•™
                if let oldContinuation = playbackCompletionContinuation {
                    oldContinuation.resume(throwing: CancellationError())
                }
                playbackCompletionContinuation = continuation
                
                // ç«‹å³æ£€æŸ¥æ˜¯å¦å·²ç»æ’­æ”¾å®Œæˆï¼ˆé˜²æ­¢ç«æ€æ¡ä»¶ï¼‰
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.01) {
                    if self.audioPlayer?.isPlaying == false {
                        // å·²ç»å®Œæˆæ’­æ”¾ï¼Œç«‹å³è§¦å‘
                        if let cont = self.playbackCompletionContinuation {
                            self.playbackCompletionContinuation = nil
                            cont.resume()
                        }
                    }
                }
            }
            
            let totalWaitDuration = Date().timeIntervalSince(waitStartTime) * 1000
            timingLog("â° [AudioService] âœ… Playback completed via delegate callback after \(String(format: "%.0fms", totalWaitDuration))")
            
            // Stop progress tracking
            stopPlaybackProgressTracking()
            
            // Notify completion
            onPlaybackComplete?()
            
            // Keep audio session active for subsequent recording operations
            debugLog("â° [AudioService] ğŸµ Playback completed, keeping audio session active for recording")
            
        } catch {
            let isCancellation = error is CancellationError
            if isCancellation {
                print("â° [AudioService] âš ï¸ playAudio() cancelled: \(error.localizedDescription)")
            } else {
                print("â° [AudioService] âŒ playAudio() failed with error: \(error.localizedDescription)")
            }

            isPlaying = false
            stopPlaybackProgressTracking()

            if let continuation = playbackCompletionContinuation {
                playbackCompletionContinuation = nil
                continuation.resume(throwing: error)
            }

            if isCancellation {
                throw CancellationError()
            }

            // Keep audio session active even on failure, will be deactivated when PracticeView closes
            debugLog("â° [AudioService] âš ï¸ Playback failed, keeping audio session active for cleanup by caller")

            if let audioError = error as? AudioServiceError {
                throw audioError
            }
            throw AudioServiceError.playbackFailed
        }

        timingLog("â° [AudioService] ğŸµ playAudio() method exiting")
    }
    
    private func restartPlaybackForDeviceChange() {
        guard isPlaying else { return }
        
        Task { @MainActor in
            print("ğŸ§ [AudioService] Restarting playback for audio device change")
            
            // è·å–å½“å‰æ’­æ”¾çŠ¶æ€
            let currentTime = self.audioPlayer?.currentTime ?? 0
            let url = self.audioPlayer?.url
            
            if let audioURL = url {
                print("ğŸ§ [AudioService] Recreating audio player for device routing")
                
                do {
                    // ç›´æ¥åœæ­¢å½“å‰æ’­æ”¾å™¨ä½†ä¸æ¸…ç†continuation
                    self.audioPlayer?.stop()
                    
                    // é‡æ–°åˆ›å»ºæ’­æ”¾å™¨ä»¥ä½¿ç”¨æ–°çš„éŸ³é¢‘è·¯ç”±
                    self.audioPlayer = try AVAudioPlayer(contentsOf: audioURL)
                    self.audioPlayer?.delegate = self
                    self.audioPlayer?.prepareToPlay()
                    self.audioPlayer?.currentTime = currentTime
                    self.audioPlayer?.play()
                    
                    print("ğŸ§ [AudioService] Audio player recreated and resumed at \(String(format: "%.1f", currentTime))s")
                } catch {
                    print("ğŸ§ [AudioService] Failed to recreate audio player: \(error.localizedDescription)")
                    // å¦‚æœé‡æ–°åˆ›å»ºå¤±è´¥ï¼Œåˆ™å®Œå…¨åœæ­¢æ’­æ”¾
                    self.stopPlayback(reason: .error)
                }
            }
        }
    }
    
    func stopPlayback() {
        stopPlayback(reason: .userRequested)
    }
    
    func stopPlayback(reason: PlaybackStopReason) {
        audioPlayer?.stop()
        audioPlayer = nil
        isPlaying = false
        stopPlaybackProgressTracking()
        
        // æ¸…ç†æ’­æ”¾å®Œæˆcontinuation
        if let continuation = playbackCompletionContinuation {
            playbackCompletionContinuation = nil
            
            switch reason {
            case .deviceDisconnected:
                // è®¾å¤‡æ–­å¼€æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸åº”è¯¥æŠ›å‡ºé”™è¯¯
                print("ğŸ§ [AudioService] Playback stopped due to device disconnection - completing normally")
                continuation.resume()
            case .userRequested, .error:
                // ç”¨æˆ·è¯·æ±‚åœæ­¢æˆ–å‡ºé”™æ—¶æŠ›å‡ºå–æ¶ˆé”™è¯¯
                continuation.resume(throwing: CancellationError())
            }
        }
    }
    
    enum PlaybackStopReason {
        case userRequested
        case deviceDisconnected  
        case error
    }
    
    private func startPlaybackProgressTracking() {
        stopPlaybackProgressTracking() // Stop any existing timer
        
        debugLog("ğŸµ [AudioService] Starting playback progress tracking")
        
        // Ensure timer runs on main queue for UI updates
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            self.playbackProgressTimer = Timer.scheduledTimer(withTimeInterval: 0.05, repeats: true) { [weak self] _ in
                guard let self = self,
                      let player = self.audioPlayer else { 
                    debugLog("ğŸµ [AudioService] âš ï¸ Progress tracking callback: no player available")
                    return 
                }
                
                let currentTime = player.currentTime
                let duration = player.duration
                
                // æ¯ç§’åªæ‰“å°ä¸€æ¬¡è¿›åº¦æ—¥å¿—ï¼Œå‡å°‘å™ªéŸ³
                if Int(currentTime) != Int(currentTime - 0.1) {
                    debugLog("ğŸµ [AudioService] Progress: \(String(format: "%.1f", currentTime))/\(String(format: "%.1f", duration))s")
                }
                
                if let callback = self.onPlaybackProgress {
                    callback(currentTime, duration)
                    // Note: Removed frequent callback success log to reduce noise
                }
                // Note: Removed missing callback warning as it may occur normally during replay
            }
            
            // Add timer to main run loop
            RunLoop.main.add(self.playbackProgressTimer!, forMode: .common)
        }
    }
    
    private func stopPlaybackProgressTracking() {
        DispatchQueue.main.async { [weak self] in
            self?.playbackProgressTimer?.invalidate()
            self?.playbackProgressTimer = nil
            debugLog("ğŸµ [AudioService] Stopped playback progress tracking")
        }
    }
}

extension AudioService: AVAudioRecorderDelegate {
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        isRecording = false
        recordingTimer?.invalidate()
        recordingTimer = nil
    }
}

extension AudioService: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        debugLog("â° [AudioService] ğŸµ AVAudioPlayerDelegate: playback finished successfully=\(flag)")
        isPlaying = false
        audioPlayer = nil
        
        // ç«‹å³é€šè¿‡continuationè§¦å‘æ’­æ”¾å®Œæˆ
        if let continuation = playbackCompletionContinuation {
            playbackCompletionContinuation = nil
            if flag {
                continuation.resume()
            } else {
                continuation.resume(throwing: AudioServiceError.playbackFailed)
            }
        }
    }
}

enum AudioServiceError: LocalizedError {
    case recordingFailed
    case playbackFailed
    case permissionDenied
    
    var errorDescription: String? {
        switch self {
        case .recordingFailed:
            return "Failed to start recording"
        case .playbackFailed:
            return "Failed to play audio"
        case .permissionDenied:
            return "Microphone permission denied"
        }
    }
}

// MARK: - Audio Session Manager

@Observable
class AudioSessionManager {
    static let shared = AudioSessionManager()
    
    private let audioSession = AVAudioSession.sharedInstance()
    
    // ç»Ÿä¸€çš„è“ç‰™è®¾å¤‡æ£€æµ‹å‡½æ•°
    private func isBluetoothOutput(_ portType: AVAudioSession.Port) -> Bool {
        return portType == .bluetoothA2DP || 
               portType == .bluetoothHFP || 
               portType == .bluetoothLE
    }
    
    /// åˆ¤æ–­æ˜¯å¦è¿æ¥äº†è€³æœºï¼ˆåŒ…å«æœ‰çº¿è€³æœºä¸è“ç‰™è€³æœºï¼‰ã€‚
    /// è§„åˆ™ï¼š
    /// - æœ‰çº¿è€³æœºï¼šè¾“å‡ºåŒ…å« .headphones
    /// - è“ç‰™è€³æœºï¼šè¾“å‡ºä¸ºè“ç‰™ç«¯å£ï¼Œä¸”è¾“å…¥ä¹Ÿå­˜åœ¨è“ç‰™ï¼ˆé€šå¸¸ä»£è¡¨å¸¦éº¦å…‹é£çš„è€³æœºï¼‰ã€‚
    /// - è“ç‰™éŸ³ç®±ï¼šä»…è“ç‰™è¾“å‡ºè€Œæ— è“ç‰™è¾“å…¥ï¼Œåˆ™ä¸è§†ä¸ºè€³æœºã€‚
    func isHeadsetConnected() -> Bool {
        let route = audioSession.currentRoute
        let hasWiredHeadphones = route.outputs.contains { $0.portType == .headphones }
        let hasBluetoothOutput = route.outputs.contains { isBluetoothOutput($0.portType) }
        let hasBluetoothInput = route.inputs.contains { input in
            input.portType == .bluetoothHFP || input.portType == .bluetoothLE
        }
        let isBluetoothHeadset = hasBluetoothOutput && hasBluetoothInput
        return hasWiredHeadphones || isBluetoothHeadset
    }
    private var recordingWarmupRecorder: AVAudioRecorder?
    private var initializationError: Error?
    
    // Re-entry protection for audio session reconfiguration
    private var isReconfiguring = false
    private let reconfigurationQueue = DispatchQueue(label: "com.selflie.audio.reconfiguration", qos: .userInitiated)
    
    // Callback for notifying audio service of playback interruptions
    var playbackInterruptionHandler: ((AVAudioSession.RouteChangeReason) -> Void)?
    
    // Callback for notifying audio service to restart playback when new device becomes available
    var playbackRestartHandler: (() -> Void)?
    
    private init() {
        setupAudioSession()
        setupRouteChangeObserver()
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self, name: AVAudioSession.routeChangeNotification, object: audioSession)
        print("âœ… [AudioSessionManager] Route change observer removed")
    }
    
    private func setupAudioSession() {
        do {
            // playAndRecord åœºæ™¯ä½¿ç”¨æ­£ç¡®çš„éŸ³é¢‘é€‰é¡¹ç»„åˆ
            let audioOptions: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetoothHFP]
            
            try audioSession.setCategory(.playAndRecord, mode: .default, options: audioOptions)
            // Allow haptic feedback during recording (critical for PracticeView)
            try audioSession.setAllowHapticsAndSystemSoundsDuringRecording(true)
            try audioSession.setActive(true)
            
            print("âœ… [AudioSessionManager] Audio session initialized with .defaultToSpeaker and .allowBluetooth")
            initializationError = nil // æ¸…é™¤ä»»ä½•ä¹‹å‰çš„é”™è¯¯
        } catch {
            initializationError = error
            print("âŒ [AudioSessionManager] Failed to initialize audio session: \(error.localizedDescription)")
        }
    }
    
    private func setupRouteChangeObserver() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleRouteChange(_:)),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        print("âœ… [AudioSessionManager] Route change observer registered for specific audio session")
    }
    
    @objc private func handleRouteChange(_ notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonRaw = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonRaw) else {
            print("âš ï¸ [AudioSessionManager] Route change notification received but could not parse reason")
            return
        }
        
        // Get previous route information for better decision making
        var previousRoute: AVAudioSessionRouteDescription?
        if let previousRouteObj = userInfo[AVAudioSessionRouteChangePreviousRouteKey] as? AVAudioSessionRouteDescription {
            previousRoute = previousRouteObj
        }
        
        let currentRoute = audioSession.currentRoute
        
        print("ğŸ§ [AudioSessionManager] Audio route changed - reason: \(reason)")
        debugLog("ğŸ§ [AudioSessionManager] Previous route: \(previousRoute?.outputs.map { "\($0.portName) (\($0.portType.rawValue))" } ?? ["None"])")
        debugLog("ğŸ§ [AudioSessionManager] Current route: \(currentRoute.outputs.map { "\($0.portName) (\($0.portType.rawValue))" })")
        
        switch reason {
        case .oldDeviceUnavailable:
            print("ğŸ§ [AudioSessionManager] Device disconnected - handling playback and reconfiguring")
            // Notify audio service to handle playback interruption
            notifyPlaybackInterruption(reason: reason)
            // é‡æ–°é…ç½®éŸ³é¢‘ä¼šè¯ä»¥é€‚åº”è®¾å¤‡ç§»é™¤ï¼ˆä»è“ç‰™åˆ‡æ¢å›æ‰¬å£°å™¨ï¼‰
            Task { @MainActor in
                await reconfigureAudioSessionForCurrentRoute()
            }
            
        case .newDeviceAvailable, .routeConfigurationChange:
            print("ğŸ§ [AudioSessionManager] Route change detected - checking for Bluetooth")
            
            // ä½¿ç”¨ç»Ÿä¸€çš„è“ç‰™æ£€æµ‹å‡½æ•°æ£€æŸ¥å½“å‰è·¯ç”±
            let currentRoute = audioSession.currentRoute
            let hasBluetooth = currentRoute.outputs.contains { isBluetoothOutput($0.portType) }
            
            print("ğŸ§ [AudioSessionManager] Current route outputs:")
            for output in currentRoute.outputs {
                print("ğŸ§   - \(output.portName) (\(output.portType.rawValue))")
            }
            print("ğŸ§ [AudioSessionManager] Has Bluetooth: \(hasBluetooth)")
            
            if hasBluetooth {
                // å…³é”®ï¼šæ’¤é”€æ‰¬å£°å™¨å¼ºåˆ¶ï¼Œäº¤ç»™ç³»ç»Ÿé€‰AirPods
                do {
                    try audioSession.overrideOutputAudioPort(.none)
                    try audioSession.setActive(true)
                    print("ğŸ§ [AudioSessionManager] âœ… Cleared audio port override, system routing to Bluetooth")
                    notifyPlaybackRestart()
                } catch {
                    print("ğŸ§ [AudioSessionManager] âŒ Failed to clear override: \(error.localizedDescription)")
                }
            } else {
                print("ğŸ§ [AudioSessionManager] No Bluetooth device in current route")
            }
            
        case .categoryChange:
            debugLog("ğŸ§ [AudioSessionManager] Audio category changed - no action needed")
            // Skip reconfiguration to avoid routing conflicts
            
        case .override:
            debugLog("ğŸ§ [AudioSessionManager] Route override - monitoring but not pausing playback")
            // Don't pause playback for override changes
            
        case .wakeFromSleep:
            debugLog("ğŸ§ [AudioSessionManager] Wake from sleep - no action needed")
            // Skip reconfiguration to avoid routing conflicts
            
        case .noSuitableRouteForCategory:
            print("ğŸ§ [AudioSessionManager] No suitable route for category - handling error")
            // This might need special error handling
            
        default:
            print("ğŸ§ [AudioSessionManager] Route change reason '\(reason)' - no specific action needed")
        }
    }
    
    private func notifyPlaybackInterruption(reason: AVAudioSession.RouteChangeReason) {
        playbackInterruptionHandler?(reason)
    }
    
    private func notifyPlaybackRestart() {
        playbackRestartHandler?()
    }
    
    @MainActor
    private func reconfigureAudioSessionForCurrentRoute() async {
        // Re-entry protection: prevent multiple concurrent reconfigurations
        return await withCheckedContinuation { continuation in
            reconfigurationQueue.async {
                guard !self.isReconfiguring else {
                    debugLog("âš ï¸ [AudioSessionManager] Reconfiguration already in progress, skipping")
                    continuation.resume()
                    return
                }
                
                self.isReconfiguring = true
                defer { self.isReconfiguring = false }
                
                do {
                    // playAndRecord åœºæ™¯ä½¿ç”¨å›ºå®šçš„æ­£ç¡®é€‰é¡¹ç»„åˆ
                    let audioOptions: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetoothHFP]
                    
                    // Reconfigure the session with appropriate options
                    try self.audioSession.setCategory(.playAndRecord, mode: .default, options: audioOptions)
                    // å…³é”®ï¼šé‡é…ç½®åä¹Ÿè¦ä¿æŒå½•éŸ³æœŸé—´å…è®¸è§¦è§‰
                    try self.audioSession.setAllowHapticsAndSystemSoundsDuringRecording(true)
                    
                    // Query updated hardware properties after route change (Apple best practice)
                    let newSampleRate = self.audioSession.sampleRate
                    let newIOBufferDuration = self.audioSession.ioBufferDuration
                    let newInputChannels = self.audioSession.inputNumberOfChannels
                    let newOutputChannels = self.audioSession.outputNumberOfChannels
                    
                    print("âœ… [AudioSessionManager] Audio session reconfigured with .defaultToSpeaker and .allowBluetooth")
                    hardwareLog("ğŸ›ï¸ [AudioSessionManager] Updated hardware properties:")
                    hardwareLog("   Sample Rate: \(newSampleRate) Hz")
                    hardwareLog("   IO Buffer Duration: \(newIOBufferDuration) seconds")
                    hardwareLog("   Input Channels: \(newInputChannels)")
                    hardwareLog("   Output Channels: \(newOutputChannels)")
                    
                } catch {
                    print("âŒ [AudioSessionManager] Failed to reconfigure audio session: \(error.localizedDescription)")
                }
                
                continuation.resume()
            }
        }
    }
    
    func getCurrentSampleRate() -> Double {
        return audioSession.sampleRate
    }
    
    // Issue 1 Fix: AirPods audio routing support
    func isBluetoothAudioDeviceConnected() -> Bool {
        let route = AVAudioSession.sharedInstance().currentRoute
        let hasBluetoothOutput = route.outputs.contains { isBluetoothOutput($0.portType) }
        
        let hasBluetoothInput = route.inputs.contains { input in
            input.portType == .bluetoothHFP ||
            input.portType == .bluetoothLE
        }
        
        let result = hasBluetoothOutput || hasBluetoothInput
        
        // Enhanced logging for debugging
        print("ğŸ§ [AudioSessionManager] Bluetooth detection:")
        print("   Current route: \(route)")
        print("   Outputs: \(route.outputs.map { "\($0.portName) (\($0.portType.rawValue))" })")
        print("   Inputs: \(route.inputs.map { "\($0.portName) (\($0.portType.rawValue))" })")
        print("   Has Bluetooth Output: \(hasBluetoothOutput)")
        print("   Has Bluetooth Input: \(hasBluetoothInput)")
        print("   Final Result: \(result)")
        
        return result
    }
    
    func getAudioSessionOptions(hasBluetoothDevice: Bool) -> AVAudioSession.CategoryOptions {
        // playAndRecord åœºæ™¯å§‹ç»ˆä½¿ç”¨ç›¸åŒçš„é€‰é¡¹ç»„åˆ
        return [.defaultToSpeaker, .allowBluetoothHFP]
    }
    
    /// Ensure the audio session is active (session is already configured in init)
    func ensureSessionActive() async throws {

        // é¦–å…ˆæ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        if let initError = initializationError {
            print("âŒ [AudioSessionManager] Cannot ensure session active due to initialization failure")
            throw initError
        }
        
        // æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²ç»æ¿€æ´»ï¼Œé¿å…é‡å¤æ“ä½œ
        if audioSession.isOtherAudioPlaying == false && audioSession.secondaryAudioShouldBeSilencedHint == false {
            // ä¼šè¯å¯èƒ½å·²ç»æ¿€æ´»ï¼Œå…ˆæ£€æŸ¥çŠ¶æ€
            do {
                // åªåœ¨éœ€è¦æ—¶æ‰é‡æ–°æ¿€æ´»
                try audioSession.setActive(true)
                print("âœ… [AudioSessionManager] Audio session activated successfully")
            } catch {
                print("âŒ [AudioSessionManager] Failed to activate audio session: \(error.localizedDescription)")
                throw error
            }
        } else {
            print("âœ… [AudioSessionManager] Audio session already active")
        }
    }
    
    
    
    
    // forceAudioRoutingæ–¹æ³•å·²ç§»é™¤ - ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†éŸ³é¢‘è·¯ç”±
    
    func preWarmRecording(to url: URL) async throws {
        print("â° [AudioSessionManager] ğŸ”¥ Pre-warming recording (optimized)")
        let warmupStartTime = Date()
        
        // Verify current audio session compatibility with recording
        let currentCategory = audioSession.category
        if currentCategory != .playAndRecord && currentCategory != .record {
            print("â° [AudioSessionManager] âš ï¸ Current session (\(currentCategory)) may not support recording warmup")
            print("â° [AudioSessionManager] ğŸ“ Warmup will proceed but may have limited effectiveness")
        }
        
        // Optimized warmup: skip actual file recording, just prepare the audio system
        // Note: No audio session change needed during warmup - keep current session
        let systemWarmupStartTime = Date()
        
        // Create minimal warmup without file I/O
        // Use hardware-compatible sample rate
        let audioSession = AVAudioSession.sharedInstance()
        let hardwareSampleRate = audioSession.sampleRate
        
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatMPEG4AAC,
            AVSampleRateKey: hardwareSampleRate, // Use hardware sample rate
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        print("ğŸ™ï¸ [AudioSessionManager] Using hardware sample rate: \(hardwareSampleRate) Hz")
        
        do {
            // Use in-memory URL for super-fast warmup
            let tempURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent("warmup_\(UUID().uuidString).m4a")
            
            recordingWarmupRecorder = try AVAudioRecorder(url: tempURL, settings: settings)
            recordingWarmupRecorder?.prepareToRecord()
            
            // Micro-burst recording to warm up audio stack without file overhead
            recordingWarmupRecorder?.record()
            
            // Use Task.sleep for precise timing control
            try await Task.sleep(nanoseconds: 5_000_000) // 5ms micro-burst
            
            recordingWarmupRecorder?.stop()
            recordingWarmupRecorder = nil
            
            // Clean up warmup file immediately
            try? FileManager.default.removeItem(at: tempURL)
            
            let systemWarmupDuration = Date().timeIntervalSince(systemWarmupStartTime) * 1000
            print("â° [AudioSessionManager] âš¡ Audio system warmed in \(String(format: "%.0fms", systemWarmupDuration))")
            
        } catch {
            let systemWarmupDuration = Date().timeIntervalSince(systemWarmupStartTime) * 1000
            print("â° [AudioSessionManager] âš ï¸ Audio system warmup failed in \(String(format: "%.0fms", systemWarmupDuration)): \(error.localizedDescription)")
            // Don't throw - warmup failure shouldn't block the main flow
        }
        
        let totalWarmupDuration = Date().timeIntervalSince(warmupStartTime) * 1000
        print("â° [AudioSessionManager] âœ… Complete recording pre-warmup in \(String(format: "%.0fms", totalWarmupDuration))")
    }
    
    enum AudioMode {
        case playback
        case recording
        case playAndRecord
    }
    
    /// Safe reconfiguration without deactivating the session - prevents audio switching to other apps
    func reconfigureSessionSafely() async throws {
        print("â° [AudioSessionManager] ğŸ”„ Safely reconfiguring audio session (no deactivation)")
        
        recordingWarmupRecorder?.stop()
        recordingWarmupRecorder = nil
        
        // Re-entry protection: prevent multiple concurrent reconfigurations
        return await withCheckedContinuation { continuation in
            reconfigurationQueue.async {
                guard !self.isReconfiguring else {
                    debugLog("âš ï¸ [AudioSessionManager] Safe reconfiguration already in progress, skipping")
                    continuation.resume()
                    return
                }
                
                self.isReconfiguring = true
                defer { self.isReconfiguring = false }
                
                do {
                    // Reconfigure without deactivating - maintains audio control
                    let audioOptions: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetoothHFP]
                    
                    try self.audioSession.setCategory(.playAndRecord, mode: .default, options: audioOptions)
                    // å…³é”®ï¼šé‡é…ç½®åä¹Ÿè¦ä¿æŒå½•éŸ³æœŸé—´å…è®¸è§¦è§‰
                    try self.audioSession.setAllowHapticsAndSystemSoundsDuringRecording(true)
                    // Note: NOT calling setActive(false) - this prevents other apps from resuming
                    
                    // Query updated hardware properties
                    let newSampleRate = self.audioSession.sampleRate
                    let newIOBufferDuration = self.audioSession.ioBufferDuration
                    
                    print("âœ… [AudioSessionManager] Audio session safely reconfigured")
                    print("ğŸ›ï¸ [AudioSessionManager] Hardware properties: \(newSampleRate)Hz, \(newIOBufferDuration)s buffer")
                    
                } catch {
                    print("âŒ [AudioSessionManager] Failed to safely reconfigure audio session: \(error.localizedDescription)")
                }
                
                continuation.resume()
            }
        }
    }

    
    func deactivateSession() async throws {
        print("â° [AudioSessionManager] ğŸ”„ Deactivating audio session and notifying other apps")
        try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
        print("â° [AudioSessionManager] âœ… Audio session deactivated successfully")
    }
}
