import AVFoundation
import Foundation

// MARK: - Debug Configuration
private struct AudioDebugConfig {
    static let isDebugModeEnabled = false  // Set to true only for debugging
    static let enableDetailedTiming = false
    static let enableHardwarePropertyLogging = false
}

// MARK: - Debug Logging Functions
private func debugLog(_ message: String) {
    if AudioDebugConfig.isDebugModeEnabled {
        print(message)
    }
}

private func timingLog(_ message: String) {
    if AudioDebugConfig.enableDetailedTiming {
        print(message)
    }
}

private func hardwareLog(_ message: String) {
    if AudioDebugConfig.enableHardwarePropertyLogging {
        print(message)
    }
}

@Observable
class AudioService: NSObject {
    private var audioRecorder: AVAudioRecorder?
    private var audioPlayer: AVAudioPlayer?
    private var preparedRecorder: AVAudioRecorder?
    private var preWarmedTimer: Timer?
    
    // Helper function to get hardware-compatible audio settings
    private func getAudioSettings() -> [String: Any] {
        let hardwareSampleRate = AudioSessionManager.shared.getCurrentSampleRate()
        
        hardwareLog("üéôÔ∏è [AudioService] Using hardware sample rate: \(hardwareSampleRate) Hz")
        
        return [
            AVFormatIDKey: kAudioFormatMPEG4AAC,
            AVSampleRateKey: hardwareSampleRate, // Use hardware sample rate
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
    }
    
    var isRecording = false
    var isPlaying = false
    var recordingDuration: TimeInterval = 0
    
    private var recordingTimer: Timer?
    private var playbackProgressTimer: Timer?
    
    // Êí≠ÊîæÂÆåÊàêÊ£ÄÊµã‰ºòÂåñÔºö‰ΩøÁî®ContinuationÊõø‰ª£ËΩÆËØ¢
    private var playbackCompletionContinuation: CheckedContinuation<Void, Error>?
    
    // Playback progress callbacks
    var onPlaybackProgress: ((TimeInterval, TimeInterval) -> Void)?
    var onPlaybackComplete: (() -> Void)?
    
    override init() {
        super.init()
        // Audio session is now managed by AudioSessionManager
        setupPlaybackInterruptionHandler()
    }
    
    private func setupPlaybackInterruptionHandler() {
        AudioSessionManager.shared.playbackInterruptionHandler = { [weak self] reason in
            guard let self = self else { return }
            
            switch reason {
            case .oldDeviceUnavailable:
                // Switch audio route when device is disconnected - continue playback on speaker
                if self.isPlaying {
                    print("üéß [AudioService] Audio device disconnected - switching to speaker")
                    self.restartPlaybackForDeviceChange()
                }
            default:
                break
            }
        }
        
        // Ê≥®ÂÜåÊí≠ÊîæÈáçÂêØÂõûË∞É - ÂΩìÊñ∞ËÆæÂ§áËøûÊé•Êó∂ÈáçÊñ∞ÂêØÂä®Êí≠Êîæ
        AudioSessionManager.shared.playbackRestartHandler = { [weak self] in
            guard let self = self else { return }
            self.restartPlaybackForDeviceChange()
        }
    }
    
    deinit {
        recordingTimer?.invalidate()
        preWarmedTimer?.invalidate()
        playbackProgressTimer?.invalidate()
        cleanupPreparedRecording()
        
        // Ê∏ÖÁêÜÊí≠ÊîæÂÆåÊàêcontinuation
        playbackCompletionContinuation?.resume(throwing: CancellationError())
        playbackCompletionContinuation = nil
    }
    
    func requestMicrophonePermission() async -> Bool {
        await withCheckedContinuation { continuation in
            AVAudioApplication.requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
    }
    
    func prepareRecording(to url: URL) async throws {
        guard preparedRecorder == nil else { return }
        
        timingLog("‚è∞ [AudioService] üîß prepareRecording() started")
        let prepareStartTime = Date()
        
        // Ensure directory exists
        let directoryStartTime = Date()
        let directory = url.deletingLastPathComponent()
        try FileManager.default.createDirectory(at: directory, withIntermediateDirectories: true, attributes: nil)
        let directoryDuration = Date().timeIntervalSince(directoryStartTime) * 1000
        timingLog("‚è∞ [AudioService] üìÅ Directory creation in \(String(format: "%.0fms", directoryDuration))")
        
        let settings = getAudioSettings()
        
        do {
            // Create recorder
            let recorderCreateStartTime = Date()
            preparedRecorder = try AVAudioRecorder(url: url, settings: settings)
            preparedRecorder?.delegate = self
            let recorderCreateDuration = Date().timeIntervalSince(recorderCreateStartTime) * 1000
            timingLog("‚è∞ [AudioService] üéôÔ∏è AVAudioRecorder created in \(String(format: "%.0fms", recorderCreateDuration))")
            
            // Aggressively prepare recorder
            let prepareToRecordStartTime = Date()
            preparedRecorder?.prepareToRecord()
            let prepareToRecordDuration = Date().timeIntervalSince(prepareToRecordStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚ö° prepareToRecord() completed in \(String(format: "%.0fms", prepareToRecordDuration))")
            
            // Pre-warm the timer to eliminate timer creation delay later
            let timerWarmupStartTime = Date()
            preWarmedTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                // This timer will be transferred to recordingTimer when recording starts
                // For now, it does nothing but stays warm
            }
            // Immediately invalidate and keep it ready for transfer
            preWarmedTimer?.invalidate()
            preWarmedTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.recordingDuration = self.audioRecorder?.currentTime ?? 0
            }
            // Keep it paused until we need it
            preWarmedTimer?.invalidate()
            preWarmedTimer = nil // Will recreate when needed
            let timerWarmupDuration = Date().timeIntervalSince(timerWarmupStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚è±Ô∏è Timer warmup completed in \(String(format: "%.0fms", timerWarmupDuration))")
            
            let totalPrepareDuration = Date().timeIntervalSince(prepareStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚úÖ prepareRecording() completed in \(String(format: "%.0fms", totalPrepareDuration))")
        } catch {
            preparedRecorder = nil
            debugLog("‚è∞ [AudioService] ‚ùå prepareRecording() failed: \(error.localizedDescription)")
            throw AudioServiceError.recordingFailed
        }
    }
    
    func startPreparedRecording() async throws {
        timingLog("‚è∞ [AudioService] üöÄ startPreparedRecording() entered")
        let startTime = Date()
        
        guard !isRecording else { 
            debugLog("‚è∞ [AudioService] ‚ö†Ô∏è Already recording, returning")
            return 
        }
        guard let preparedRecorder = preparedRecorder else {
            debugLog("‚è∞ [AudioService] ‚ùå No prepared recorder available")
            throw AudioServiceError.recordingFailed
        }
        
        // Audio session is already configured for .playAndRecord in AudioSessionManager.init()
        // No need to switch - just ensure it's active
        try await AudioSessionManager.shared.ensureSessionActive()
        
        // Ultra-fast recording start: minimize operations
        let recordStartTime = Date()
        
        // Atomic state update and recorder transfer
        isRecording = true
        recordingDuration = 0
        audioRecorder = preparedRecorder
        self.preparedRecorder = nil
        
        // Start recording immediately - this should be instantaneous since recorder is fully prepared
        audioRecorder?.record()
        
        let recordDuration = Date().timeIntervalSince(recordStartTime) * 1000
        timingLog("‚è∞ [AudioService] ‚ö° Ultra-fast record() completed in \(String(format: "%.0fms", recordDuration))")
        
        // Use pre-warmed timer if available, otherwise create new one
        if let existingTimer = preWarmedTimer {
            timingLog("‚è∞ [AudioService] üî• Using pre-warmed timer")
            recordingTimer = existingTimer
            preWarmedTimer = nil
        } else {
            let timerStartTime = Date()
            recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.recordingDuration = self.audioRecorder?.currentTime ?? 0
            }
            let timerDuration = Date().timeIntervalSince(timerStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚è±Ô∏è New timer created in \(String(format: "%.0fms", timerDuration))")
        }
        
        let totalDuration = Date().timeIntervalSince(startTime) * 1000
        timingLog("‚è∞ [AudioService] ‚úÖ startPreparedRecording() completed in \(String(format: "%.0fms", totalDuration))")
    }
    
    func startRecording(to url: URL) async throws {
        guard !isRecording else { return }
        
        // Ensure directory exists
        let directory = url.deletingLastPathComponent()
        try FileManager.default.createDirectory(at: directory, withIntermediateDirectories: true, attributes: nil)
        
        let settings = getAudioSettings()
        
        do {
            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder?.delegate = self
            audioRecorder?.prepareToRecord()
            audioRecorder?.record()
            
            isRecording = true
            recordingDuration = 0
            
            // Start timer for duration tracking
            recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.recordingDuration = self.audioRecorder?.currentTime ?? 0
            }
        } catch {
            throw AudioServiceError.recordingFailed
        }
    }
    
    func cleanupPreparedRecording() {
        preparedRecorder = nil
        preWarmedTimer?.invalidate()
        preWarmedTimer = nil
    }
    
    func stopRecording() {
        guard isRecording else { return }
        
        audioRecorder?.stop()
        audioRecorder = nil
        isRecording = false
        
        recordingTimer?.invalidate()
        recordingTimer = nil
    }
    
    func playAudio(from url: URL, volume: Float = 1.0) async throws {
        timingLog("‚è∞ [AudioService] üéµ playAudio() method entered")
        guard !isPlaying else { 
            debugLog("‚è∞ [AudioService] ‚ö†Ô∏è Already playing, returning early")
            return 
        }
        
        // Audio session is already configured for .playAndRecord in AudioSessionManager.init()
        // No need to switch - just ensure it's active
        try await AudioSessionManager.shared.ensureSessionActive()
        
        do {
            timingLog("‚è∞ [AudioService] üîß Creating AVAudioPlayer")
            let playerCreateStartTime = Date()
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            // ÊîØÊåÅÂèØÈÄâÈü≥ÈáèÔºåÁî®‰∫éÈöêÁßÅÊ®°ÂºèÈùôÈü≥Êí≠Êîæ
            audioPlayer?.volume = volume
            audioPlayer?.prepareToPlay()
            let playerCreateDuration = Date().timeIntervalSince(playerCreateStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚úÖ AVAudioPlayer created and prepared in \(String(format: "%.0fms", playerCreateDuration))")
            
            isPlaying = true
            
            // Start progress tracking timer
            startPlaybackProgressTracking()
            
            timingLog("‚è∞ [AudioService] ‚ñ∂Ô∏è Calling audioPlayer.play()")
            let playStartTime = Date()
            audioPlayer?.play()
            let playCallDuration = Date().timeIntervalSince(playStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚úÖ audioPlayer.play() call completed in \(String(format: "%.0fms", playCallDuration))")
            
            // ‰ºòÂåñÔºö‰ΩøÁî®ContinuationÁ≠âÂæÖÊí≠ÊîæÂÆåÊàêÔºåÊõø‰ª£ËΩÆËØ¢
            timingLog("‚è∞ [AudioService] ‚è≥ Waiting for playback completion via delegate callback")
            let waitStartTime = Date()
            
            // ‰ΩøÁî®continuationÁ≠âÂæÖAVAudioPlayerDelegateÂõûË∞É
            try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
                // Á°Æ‰øùÊ≤°Êúâ‰πãÂâçÁöÑcontinuationÊÆãÁïô
                if let oldContinuation = playbackCompletionContinuation {
                    oldContinuation.resume(throwing: CancellationError())
                }
                playbackCompletionContinuation = continuation
                
                // Á´ãÂç≥Ê£ÄÊü•ÊòØÂê¶Â∑≤ÁªèÊí≠ÊîæÂÆåÊàêÔºàÈò≤Ê≠¢Á´ûÊÄÅÊù°‰ª∂Ôºâ
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.01) {
                    if self.audioPlayer?.isPlaying == false {
                        // Â∑≤ÁªèÂÆåÊàêÊí≠ÊîæÔºåÁ´ãÂç≥Ëß¶Âèë
                        if let cont = self.playbackCompletionContinuation {
                            self.playbackCompletionContinuation = nil
                            cont.resume()
                        }
                    }
                }
            }
            
            let totalWaitDuration = Date().timeIntervalSince(waitStartTime) * 1000
            timingLog("‚è∞ [AudioService] ‚úÖ Playback completed via delegate callback after \(String(format: "%.0fms", totalWaitDuration))")
            
            // Stop progress tracking
            stopPlaybackProgressTracking()
            
            // Notify completion
            onPlaybackComplete?()
            
            // Keep audio session active for subsequent recording operations
            debugLog("‚è∞ [AudioService] üéµ Playback completed, keeping audio session active for recording")
            
        } catch {
            let isCancellation = error is CancellationError
            if isCancellation {
                print("‚è∞ [AudioService] ‚ö†Ô∏è playAudio() cancelled: \(error.localizedDescription)")
            } else {
                print("‚è∞ [AudioService] ‚ùå playAudio() failed with error: \(error.localizedDescription)")
            }

            isPlaying = false
            stopPlaybackProgressTracking()

            if let continuation = playbackCompletionContinuation {
                playbackCompletionContinuation = nil
                continuation.resume(throwing: error)
            }

            if isCancellation {
                throw CancellationError()
            }

            // Keep audio session active even on failure, will be deactivated when PracticeView closes
            debugLog("‚è∞ [AudioService] ‚ö†Ô∏è Playback failed, keeping audio session active for cleanup by caller")

            if let audioError = error as? AudioServiceError {
                throw audioError
            }
            throw AudioServiceError.playbackFailed
        }

        timingLog("‚è∞ [AudioService] üéµ playAudio() method exiting")
    }
    
    private func restartPlaybackForDeviceChange() {
        guard isPlaying else { return }
        
        Task { @MainActor in
            print("üéß [AudioService] Restarting playback for audio device change")
            
            // Ëé∑ÂèñÂΩìÂâçÊí≠ÊîæÁä∂ÊÄÅ
            let currentTime = self.audioPlayer?.currentTime ?? 0
            let url = self.audioPlayer?.url
            
            if let audioURL = url {
                print("üéß [AudioService] Recreating audio player for device routing")
                
                do {
                    // Áõ¥Êé•ÂÅúÊ≠¢ÂΩìÂâçÊí≠ÊîæÂô®‰ΩÜ‰∏çÊ∏ÖÁêÜcontinuation
                    self.audioPlayer?.stop()
                    
                    // ÈáçÊñ∞ÂàõÂª∫Êí≠ÊîæÂô®‰ª•‰ΩøÁî®Êñ∞ÁöÑÈü≥È¢ëË∑ØÁî±
                    self.audioPlayer = try AVAudioPlayer(contentsOf: audioURL)
                    self.audioPlayer?.delegate = self
                    self.audioPlayer?.prepareToPlay()
                    self.audioPlayer?.currentTime = currentTime
                    self.audioPlayer?.play()
                    
                    print("üéß [AudioService] Audio player recreated and resumed at \(String(format: "%.1f", currentTime))s")
                } catch {
                    print("üéß [AudioService] Failed to recreate audio player: \(error.localizedDescription)")
                    // Â¶ÇÊûúÈáçÊñ∞ÂàõÂª∫Â§±Ë¥•ÔºåÂàôÂÆåÂÖ®ÂÅúÊ≠¢Êí≠Êîæ
                    self.stopPlayback(reason: .error)
                }
            }
        }
    }
    
    func stopPlayback() {
        stopPlayback(reason: .userRequested)
    }
    
    func stopPlayback(reason: PlaybackStopReason) {
        audioPlayer?.stop()
        audioPlayer = nil
        isPlaying = false
        stopPlaybackProgressTracking()
        
        // Ê∏ÖÁêÜÊí≠ÊîæÂÆåÊàêcontinuation
        if let continuation = playbackCompletionContinuation {
            playbackCompletionContinuation = nil
            
            switch reason {
            case .deviceDisconnected:
                // ËÆæÂ§áÊñ≠ÂºÄÊòØÊ≠£Â∏∏ÊÉÖÂÜµÔºå‰∏çÂ∫îËØ•ÊäõÂá∫ÈîôËØØ
                print("üéß [AudioService] Playback stopped due to device disconnection - completing normally")
                continuation.resume()
            case .userRequested, .error:
                // Áî®Êà∑ËØ∑Ê±ÇÂÅúÊ≠¢ÊàñÂá∫ÈîôÊó∂ÊäõÂá∫ÂèñÊ∂àÈîôËØØ
                continuation.resume(throwing: CancellationError())
            }
        }
    }
    
    enum PlaybackStopReason {
        case userRequested
        case deviceDisconnected  
        case error
    }
    
    private func startPlaybackProgressTracking() {
        stopPlaybackProgressTracking() // Stop any existing timer
        
        debugLog("üéµ [AudioService] Starting playback progress tracking")
        
        // Ensure timer runs on main queue for UI updates
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            self.playbackProgressTimer = Timer.scheduledTimer(withTimeInterval: 0.05, repeats: true) { [weak self] _ in
                guard let self = self,
                      let player = self.audioPlayer else { 
                    debugLog("üéµ [AudioService] ‚ö†Ô∏è Progress tracking callback: no player available")
                    return 
                }
                
                let currentTime = player.currentTime
                let duration = player.duration
                
                // ÊØèÁßíÂè™ÊâìÂç∞‰∏ÄÊ¨°ËøõÂ∫¶Êó•ÂøóÔºåÂáèÂ∞ëÂô™Èü≥
                if Int(currentTime) != Int(currentTime - 0.1) {
                    debugLog("üéµ [AudioService] Progress: \(String(format: "%.1f", currentTime))/\(String(format: "%.1f", duration))s")
                }
                
                if let callback = self.onPlaybackProgress {
                    callback(currentTime, duration)
                    // Note: Removed frequent callback success log to reduce noise
                }
                // Note: Removed missing callback warning as it may occur normally during replay
            }
            
            // Add timer to main run loop
            RunLoop.main.add(self.playbackProgressTimer!, forMode: .common)
        }
    }
    
    private func stopPlaybackProgressTracking() {
        DispatchQueue.main.async { [weak self] in
            self?.playbackProgressTimer?.invalidate()
            self?.playbackProgressTimer = nil
            debugLog("üéµ [AudioService] Stopped playback progress tracking")
        }
    }
}

extension AudioService: AVAudioRecorderDelegate {
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        isRecording = false
        recordingTimer?.invalidate()
        recordingTimer = nil
    }
}

extension AudioService: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        debugLog("‚è∞ [AudioService] üéµ AVAudioPlayerDelegate: playback finished successfully=\(flag)")
        isPlaying = false
        audioPlayer = nil
        
        // Á´ãÂç≥ÈÄöËøácontinuationËß¶ÂèëÊí≠ÊîæÂÆåÊàê
        if let continuation = playbackCompletionContinuation {
            playbackCompletionContinuation = nil
            if flag {
                continuation.resume()
            } else {
                continuation.resume(throwing: AudioServiceError.playbackFailed)
            }
        }
    }
}

enum AudioServiceError: LocalizedError {
    case recordingFailed
    case playbackFailed
    case permissionDenied
    
    var errorDescription: String? {
        switch self {
        case .recordingFailed:
            return "Failed to start recording"
        case .playbackFailed:
            return "Failed to play audio"
        case .permissionDenied:
            return "Microphone permission denied"
        }
    }
}

// MARK: - Audio Session Manager

@Observable
class AudioSessionManager {
    static let shared = AudioSessionManager()
    
    private let audioSession = AVAudioSession.sharedInstance()
    
    // Áªü‰∏ÄÁöÑËìùÁâôËÆæÂ§áÊ£ÄÊµãÂáΩÊï∞
    private func isBluetoothOutput(_ portType: AVAudioSession.Port) -> Bool {
        return portType == .bluetoothA2DP || 
               portType == .bluetoothHFP || 
               portType == .bluetoothLE
    }
    
    /// Âà§Êñ≠ÊòØÂê¶ËøûÊé•‰∫ÜËÄ≥Êú∫ÔºàÂåÖÂê´ÊúâÁ∫øËÄ≥Êú∫‰∏éËìùÁâôËÄ≥Êú∫Ôºâ„ÄÇ
    /// ËßÑÂàôÔºö
    /// - ÊúâÁ∫øËÄ≥Êú∫ÔºöËæìÂá∫ÂåÖÂê´ .headphones
    /// - ËìùÁâôËÄ≥Êú∫ÔºöËæìÂá∫‰∏∫ËìùÁâôÁ´ØÂè£Ôºå‰∏îËæìÂÖ•‰πüÂ≠òÂú®ËìùÁâôÔºàÈÄöÂ∏∏‰ª£Ë°®Â∏¶È∫¶ÂÖãÈ£éÁöÑËÄ≥Êú∫Ôºâ„ÄÇ
    /// - ËìùÁâôÈü≥ÁÆ±Ôºö‰ªÖËìùÁâôËæìÂá∫ËÄåÊó†ËìùÁâôËæìÂÖ•ÔºåÂàô‰∏çËßÜ‰∏∫ËÄ≥Êú∫„ÄÇ
    func isHeadsetConnected() -> Bool {
        let route = audioSession.currentRoute
        let hasWiredHeadphones = route.outputs.contains { $0.portType == .headphones }
        let hasBluetoothOutput = route.outputs.contains { isBluetoothOutput($0.portType) }
        let hasBluetoothInput = route.inputs.contains { input in
            input.portType == .bluetoothHFP || input.portType == .bluetoothLE
        }
        let isBluetoothHeadset = hasBluetoothOutput && hasBluetoothInput
        return hasWiredHeadphones || isBluetoothHeadset
    }
    private var recordingWarmupRecorder: AVAudioRecorder?
    private var initializationError: Error?
    
    // Re-entry protection for audio session reconfiguration
    private var isReconfiguring = false
    private let reconfigurationQueue = DispatchQueue(label: "com.selflie.audio.reconfiguration", qos: .userInitiated)
    
    // Callback for notifying audio service of playback interruptions
    var playbackInterruptionHandler: ((AVAudioSession.RouteChangeReason) -> Void)?
    
    // Callback for notifying audio service to restart playback when new device becomes available
    var playbackRestartHandler: (() -> Void)?
    
    private init() {
        setupAudioSession()
        setupRouteChangeObserver()
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self, name: AVAudioSession.routeChangeNotification, object: audioSession)
        print("‚úÖ [AudioSessionManager] Route change observer removed")
    }
    
    private func setupAudioSession() {
        do {
            // playAndRecord Âú∫ÊôØ‰ΩøÁî®Ê≠£Á°ÆÁöÑÈü≥È¢ëÈÄâÈ°πÁªÑÂêà
            let audioOptions: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetoothHFP]
            
            try audioSession.setCategory(.playAndRecord, mode: .default, options: audioOptions)
            // Allow haptic feedback during recording (critical for PracticeView)
            try audioSession.setAllowHapticsAndSystemSoundsDuringRecording(true)
            try audioSession.setActive(true)
            
            print("‚úÖ [AudioSessionManager] Audio session initialized with .defaultToSpeaker and .allowBluetooth")
            initializationError = nil // Ê∏ÖÈô§‰ªª‰Ωï‰πãÂâçÁöÑÈîôËØØ
        } catch {
            initializationError = error
            print("‚ùå [AudioSessionManager] Failed to initialize audio session: \(error.localizedDescription)")
        }
    }
    
    private func setupRouteChangeObserver() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleRouteChange(_:)),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        print("‚úÖ [AudioSessionManager] Route change observer registered for specific audio session")
    }
    
    @objc private func handleRouteChange(_ notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonRaw = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonRaw) else {
            print("‚ö†Ô∏è [AudioSessionManager] Route change notification received but could not parse reason")
            return
        }
        
        // Get previous route information for better decision making
        var previousRoute: AVAudioSessionRouteDescription?
        if let previousRouteObj = userInfo[AVAudioSessionRouteChangePreviousRouteKey] as? AVAudioSessionRouteDescription {
            previousRoute = previousRouteObj
        }
        
        let currentRoute = audioSession.currentRoute
        
        print("üéß [AudioSessionManager] Audio route changed - reason: \(reason)")
        debugLog("üéß [AudioSessionManager] Previous route: \(previousRoute?.outputs.map { "\($0.portName) (\($0.portType.rawValue))" } ?? ["None"])")
        debugLog("üéß [AudioSessionManager] Current route: \(currentRoute.outputs.map { "\($0.portName) (\($0.portType.rawValue))" })")
        
        switch reason {
        case .oldDeviceUnavailable:
            print("üéß [AudioSessionManager] Device disconnected - handling playback and reconfiguring")
            // Notify audio service to handle playback interruption
            notifyPlaybackInterruption(reason: reason)
            // ÈáçÊñ∞ÈÖçÁΩÆÈü≥È¢ë‰ºöËØù‰ª•ÈÄÇÂ∫îËÆæÂ§áÁßªÈô§Ôºà‰ªéËìùÁâôÂàáÊç¢ÂõûÊâ¨Â£∞Âô®Ôºâ
            Task { @MainActor in
                await reconfigureAudioSessionForCurrentRoute()
            }
            
        case .newDeviceAvailable, .routeConfigurationChange:
            print("üéß [AudioSessionManager] Route change detected - checking for Bluetooth")
            
            // ‰ΩøÁî®Áªü‰∏ÄÁöÑËìùÁâôÊ£ÄÊµãÂáΩÊï∞Ê£ÄÊü•ÂΩìÂâçË∑ØÁî±
            let currentRoute = audioSession.currentRoute
            let hasBluetooth = currentRoute.outputs.contains { isBluetoothOutput($0.portType) }
            
            print("üéß [AudioSessionManager] Current route outputs:")
            for output in currentRoute.outputs {
                print("üéß   - \(output.portName) (\(output.portType.rawValue))")
            }
            print("üéß [AudioSessionManager] Has Bluetooth: \(hasBluetooth)")
            
            if hasBluetooth {
                // ÂÖ≥ÈîÆÔºöÊí§ÈîÄÊâ¨Â£∞Âô®Âº∫Âà∂Ôºå‰∫§ÁªôÁ≥ªÁªüÈÄâAirPods
                do {
                    try audioSession.overrideOutputAudioPort(.none)
                    try audioSession.setActive(true)
                    print("üéß [AudioSessionManager] ‚úÖ Cleared audio port override, system routing to Bluetooth")
                    notifyPlaybackRestart()
                } catch {
                    print("üéß [AudioSessionManager] ‚ùå Failed to clear override: \(error.localizedDescription)")
                }
            } else {
                print("üéß [AudioSessionManager] No Bluetooth device in current route")
            }
            
        case .categoryChange:
            debugLog("üéß [AudioSessionManager] Audio category changed - no action needed")
            // Skip reconfiguration to avoid routing conflicts
            
        case .override:
            debugLog("üéß [AudioSessionManager] Route override - monitoring but not pausing playback")
            // Don't pause playback for override changes
            
        case .wakeFromSleep:
            debugLog("üéß [AudioSessionManager] Wake from sleep - no action needed")
            // Skip reconfiguration to avoid routing conflicts
            
        case .noSuitableRouteForCategory:
            print("üéß [AudioSessionManager] No suitable route for category - handling error")
            // This might need special error handling
            
        default:
            print("üéß [AudioSessionManager] Route change reason '\(reason)' - no specific action needed")
        }
    }
    
    private func notifyPlaybackInterruption(reason: AVAudioSession.RouteChangeReason) {
        playbackInterruptionHandler?(reason)
    }
    
    private func notifyPlaybackRestart() {
        playbackRestartHandler?()
    }
    
    @MainActor
    private func reconfigureAudioSessionForCurrentRoute() async {
        // Re-entry protection: prevent multiple concurrent reconfigurations
        return await withCheckedContinuation { continuation in
            reconfigurationQueue.async {
                guard !self.isReconfiguring else {
                    debugLog("‚ö†Ô∏è [AudioSessionManager] Reconfiguration already in progress, skipping")
                    continuation.resume()
                    return
                }
                
                self.isReconfiguring = true
                defer { self.isReconfiguring = false }
                
                do {
                    // playAndRecord Âú∫ÊôØ‰ΩøÁî®Âõ∫ÂÆöÁöÑÊ≠£Á°ÆÈÄâÈ°πÁªÑÂêà
                    let audioOptions: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetoothHFP]
                    
                    // Reconfigure the session with appropriate options
                    try self.audioSession.setCategory(.playAndRecord, mode: .default, options: audioOptions)
                    // ÂÖ≥ÈîÆÔºöÈáçÈÖçÁΩÆÂêé‰πüË¶Å‰øùÊåÅÂΩïÈü≥ÊúüÈó¥ÂÖÅËÆ∏Ëß¶Ëßâ
                    try self.audioSession.setAllowHapticsAndSystemSoundsDuringRecording(true)
                    
                    // Query updated hardware properties after route change (Apple best practice)
                    let newSampleRate = self.audioSession.sampleRate
                    let newIOBufferDuration = self.audioSession.ioBufferDuration
                    let newInputChannels = self.audioSession.inputNumberOfChannels
                    let newOutputChannels = self.audioSession.outputNumberOfChannels
                    
                    print("‚úÖ [AudioSessionManager] Audio session reconfigured with .defaultToSpeaker and .allowBluetooth")
                    hardwareLog("üéõÔ∏è [AudioSessionManager] Updated hardware properties:")
                    hardwareLog("   Sample Rate: \(newSampleRate) Hz")
                    hardwareLog("   IO Buffer Duration: \(newIOBufferDuration) seconds")
                    hardwareLog("   Input Channels: \(newInputChannels)")
                    hardwareLog("   Output Channels: \(newOutputChannels)")
                    
                } catch {
                    print("‚ùå [AudioSessionManager] Failed to reconfigure audio session: \(error.localizedDescription)")
                }
                
                continuation.resume()
            }
        }
    }
    
    func getCurrentSampleRate() -> Double {
        return audioSession.sampleRate
    }
    
    // Issue 1 Fix: AirPods audio routing support
    func isBluetoothAudioDeviceConnected() -> Bool {
        let route = AVAudioSession.sharedInstance().currentRoute
        let hasBluetoothOutput = route.outputs.contains { isBluetoothOutput($0.portType) }
        
        let hasBluetoothInput = route.inputs.contains { input in
            input.portType == .bluetoothHFP ||
            input.portType == .bluetoothLE
        }
        
        let result = hasBluetoothOutput || hasBluetoothInput
        
        // Enhanced logging for debugging
        print("üéß [AudioSessionManager] Bluetooth detection:")
        print("   Current route: \(route)")
        print("   Outputs: \(route.outputs.map { "\($0.portName) (\($0.portType.rawValue))" })")
        print("   Inputs: \(route.inputs.map { "\($0.portName) (\($0.portType.rawValue))" })")
        print("   Has Bluetooth Output: \(hasBluetoothOutput)")
        print("   Has Bluetooth Input: \(hasBluetoothInput)")
        print("   Final Result: \(result)")
        
        return result
    }
    
    func getAudioSessionOptions(hasBluetoothDevice: Bool) -> AVAudioSession.CategoryOptions {
        // playAndRecord Âú∫ÊôØÂßãÁªà‰ΩøÁî®Áõ∏ÂêåÁöÑÈÄâÈ°πÁªÑÂêà
        return [.defaultToSpeaker, .allowBluetoothHFP]
    }
    
    /// Ensure the audio session is active (session is already configured in init)
    func ensureSessionActive() async throws {

        // È¶ñÂÖàÊ£ÄÊü•ÂàùÂßãÂåñÊòØÂê¶ÊàêÂäü
        if let initError = initializationError {
            print("‚ùå [AudioSessionManager] Cannot ensure session active due to initialization failure")
            throw initError
        }
        
        // Ê£ÄÊü•‰ºöËØùÊòØÂê¶Â∑≤ÁªèÊøÄÊ¥ªÔºåÈÅøÂÖçÈáçÂ§çÊìç‰Ωú
        if audioSession.isOtherAudioPlaying == false && audioSession.secondaryAudioShouldBeSilencedHint == false {
            // ‰ºöËØùÂèØËÉΩÂ∑≤ÁªèÊøÄÊ¥ªÔºåÂÖàÊ£ÄÊü•Áä∂ÊÄÅ
            do {
                // Âè™Âú®ÈúÄË¶ÅÊó∂ÊâçÈáçÊñ∞ÊøÄÊ¥ª
                try audioSession.setActive(true)
                print("‚úÖ [AudioSessionManager] Audio session activated successfully")
            } catch {
                print("‚ùå [AudioSessionManager] Failed to activate audio session: \(error.localizedDescription)")
                throw error
            }
        } else {
            print("‚úÖ [AudioSessionManager] Audio session already active")
        }
    }
    
    
    
    
    // forceAudioRoutingÊñπÊ≥ïÂ∑≤ÁßªÈô§ - Á≥ªÁªü‰ºöËá™Âä®Â§ÑÁêÜÈü≥È¢ëË∑ØÁî±
    
    func preWarmRecording(to url: URL) async throws {
        print("‚è∞ [AudioSessionManager] üî• Pre-warming recording (optimized)")
        let warmupStartTime = Date()
        
        // Verify current audio session compatibility with recording
        let currentCategory = audioSession.category
        if currentCategory != .playAndRecord && currentCategory != .record {
            print("‚è∞ [AudioSessionManager] ‚ö†Ô∏è Current session (\(currentCategory)) may not support recording warmup")
            print("‚è∞ [AudioSessionManager] üìù Warmup will proceed but may have limited effectiveness")
        }
        
        // Optimized warmup: skip actual file recording, just prepare the audio system
        // Note: No audio session change needed during warmup - keep current session
        let systemWarmupStartTime = Date()
        
        // Create minimal warmup without file I/O
        // Use hardware-compatible sample rate
        let audioSession = AVAudioSession.sharedInstance()
        let hardwareSampleRate = audioSession.sampleRate
        
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatMPEG4AAC,
            AVSampleRateKey: hardwareSampleRate, // Use hardware sample rate
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        print("üéôÔ∏è [AudioSessionManager] Using hardware sample rate: \(hardwareSampleRate) Hz")
        
        do {
            // Use in-memory URL for super-fast warmup
            let tempURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent("warmup_\(UUID().uuidString).m4a")
            
            recordingWarmupRecorder = try AVAudioRecorder(url: tempURL, settings: settings)
            recordingWarmupRecorder?.prepareToRecord()
            
            // Micro-burst recording to warm up audio stack without file overhead
            recordingWarmupRecorder?.record()
            
            // Use Task.sleep for precise timing control
            try await Task.sleep(nanoseconds: 5_000_000) // 5ms micro-burst
            
            recordingWarmupRecorder?.stop()
            recordingWarmupRecorder = nil
            
            // Clean up warmup file immediately
            try? FileManager.default.removeItem(at: tempURL)
            
            let systemWarmupDuration = Date().timeIntervalSince(systemWarmupStartTime) * 1000
            print("‚è∞ [AudioSessionManager] ‚ö° Audio system warmed in \(String(format: "%.0fms", systemWarmupDuration))")
            
        } catch {
            let systemWarmupDuration = Date().timeIntervalSince(systemWarmupStartTime) * 1000
            print("‚è∞ [AudioSessionManager] ‚ö†Ô∏è Audio system warmup failed in \(String(format: "%.0fms", systemWarmupDuration)): \(error.localizedDescription)")
            // Don't throw - warmup failure shouldn't block the main flow
        }
        
        let totalWarmupDuration = Date().timeIntervalSince(warmupStartTime) * 1000
        print("‚è∞ [AudioSessionManager] ‚úÖ Complete recording pre-warmup in \(String(format: "%.0fms", totalWarmupDuration))")
    }
    
    enum AudioMode {
        case playback
        case recording
        case playAndRecord
    }
    
    /// Safe reconfiguration without deactivating the session - prevents audio switching to other apps
    func reconfigureSessionSafely() async throws {
        print("‚è∞ [AudioSessionManager] üîÑ Safely reconfiguring audio session (no deactivation)")
        
        recordingWarmupRecorder?.stop()
        recordingWarmupRecorder = nil
        
        // Re-entry protection: prevent multiple concurrent reconfigurations
        return await withCheckedContinuation { continuation in
            reconfigurationQueue.async {
                guard !self.isReconfiguring else {
                    debugLog("‚ö†Ô∏è [AudioSessionManager] Safe reconfiguration already in progress, skipping")
                    continuation.resume()
                    return
                }
                
                self.isReconfiguring = true
                defer { self.isReconfiguring = false }
                
                do {
                    // Reconfigure without deactivating - maintains audio control
                    let audioOptions: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetoothHFP]
                    
                    try self.audioSession.setCategory(.playAndRecord, mode: .default, options: audioOptions)
                    // ÂÖ≥ÈîÆÔºöÈáçÈÖçÁΩÆÂêé‰πüË¶Å‰øùÊåÅÂΩïÈü≥ÊúüÈó¥ÂÖÅËÆ∏Ëß¶Ëßâ
                    try self.audioSession.setAllowHapticsAndSystemSoundsDuringRecording(true)
                    // Note: NOT calling setActive(false) - this prevents other apps from resuming
                    
                    // Query updated hardware properties
                    let newSampleRate = self.audioSession.sampleRate
                    let newIOBufferDuration = self.audioSession.ioBufferDuration
                    
                    print("‚úÖ [AudioSessionManager] Audio session safely reconfigured")
                    print("üéõÔ∏è [AudioSessionManager] Hardware properties: \(newSampleRate)Hz, \(newIOBufferDuration)s buffer")
                    
                } catch {
                    print("‚ùå [AudioSessionManager] Failed to safely reconfigure audio session: \(error.localizedDescription)")
                }
                
                continuation.resume()
            }
        }
    }

    
    func deactivateSession() async throws {
        print("‚è∞ [AudioSessionManager] üîÑ Deactivating audio session and notifying other apps")
        try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
        print("‚è∞ [AudioSessionManager] ‚úÖ Audio session deactivated successfully")
    }
}
